{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3a0d4f-d325-42de-a7e3-3accbba18957",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies and Setup\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import time\n",
    "from scipy.stats import linregress\n",
    "\n",
    "\n",
    "# Import the OMDB API key\n",
    "from api_keys import omdb_api_key\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c6eebf0-05f6-4e2f-aecc-abb2ce804a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data files\n",
    "netflix_path = \"../data/netflix_titles.csv\"\n",
    "disney_path = \"../data/disney_plus_titles.csv\"\n",
    "prices_path = \"../data/subscription_prices.csv\"\n",
    "\n",
    "# Read the Netflix and Disney+ data\n",
    "netflix_data = pd.read_csv(netflix_path)\n",
    "disney_data = pd.read_csv(disney_path)\n",
    "prices_data = pd.read_csv(prices_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ec2244-9780-4525-a40c-879606dd26c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Netflix dataframe and review length\n",
    "netflix_df = pd.DataFrame(netflix_data)\n",
    "len(netflix_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304e048d-833f-4efb-94e2-d1eeca9afadd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Netflix date_added is the key column for filtering to 2019 - 2021 to align with Disney+ dataset date_added dates\n",
    "# The following steps trim the \"September 24, 2018\" dates to remove extra spaces\n",
    "netflix_df['date_added'] = netflix_df['date_added'].str.strip()\n",
    "# netflix_df['date_added'] = pd.to_datetime(netflix_df['date_added'], errors='coerce')\n",
    "\n",
    "# There are a handful of blank date_added that will impact date filtering\n",
    "netflix_blank_dates = netflix_df[netflix_df['date_added'].isna()]\n",
    "len(netflix_blank_dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7a14de-654e-4728-926f-33754fce0557",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with blank dates\n",
    "netflix_df = netflix_df.dropna(subset=['date_added'])\n",
    "\n",
    "# Verify the number of rows with blank dates after dropping\n",
    "len(netflix_df[netflix_df['date_added'].isna()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e576bc-1857-4e9a-91c6-3134a474a993",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract only the date portion and convert it to string\n",
    "netflix_df['date_added'] = pd.to_datetime(netflix_df['date_added'], errors='coerce')\n",
    "netflix_df['date_added'] = netflix_df['date_added'].dt.date.astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d51d48f-85ff-4b88-bc7b-4841bad0f1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out for dates greater than January 1, 2019\n",
    "netflix_df = netflix_df.loc[(netflix_df['date_added'] >= '2019-01-01') & (netflix_df['date_added'] <= '2021-12-31')]\n",
    "len(netflix_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f5ac4b-5ad4-4347-8af3-2a8ad3a78844",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Disney+ dataframe and review length\n",
    "disney_df = pd.DataFrame(disney_data)\n",
    "len(disney_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd66992b-2b25-42a5-ac1c-5e45813d8801",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are a handful of blank date_added that will impact data\n",
    "disney_blank_dates = disney_df[disney_df['date_added'].isna()]\n",
    "len(disney_blank_dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00707854-6ed7-4565-9eca-a4d269603371",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with blank dates\n",
    "disney_df = disney_df.dropna(subset=['date_added'])\n",
    "\n",
    "# Verify the number of rows with blank dates after dropping\n",
    "len(disney_df[disney_df['date_added'].isna()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "998924cd-c132-462c-8ffb-67c5f44c5067",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract only the date portion and convert it to string\n",
    "disney_df['date_added'] = pd.to_datetime(disney_df['date_added'], errors='coerce')\n",
    "disney_df['date_added'] = disney_df['date_added'].dt.date.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1bffdd1-fafa-4e52-a8c4-197538c760fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorted data frames by date_added\n",
    "sorted_netflix_df = netflix_df.sort_values(by = 'date_added', ascending=False)\n",
    "sorted_disney_df = disney_df.sort_values(by = 'date_added', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211f2344-0350-4e4d-8806-325e44289063",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Most recent 500 titles per platform\n",
    "recentadd_netflix_df = sorted_netflix_df.head(500)\n",
    "recentadd_disney_df = sorted_disney_df.head(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60ee9cd-4fa7-41ed-9bfe-ee5eda915b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Subscription Price dataframe and review length\n",
    "prices_df = pd.DataFrame(prices_data)\n",
    "len(prices_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11084ac8-17f2-4e6e-8b62-4a4a755937bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-establishing filtered DataFrame as primary DataFrame for analysis\n",
    "netflix_df = recentadd_netflix_df\n",
    "disney_df = recentadd_disney_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c319f08-e34d-4719-8408-c6ebb8f209f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add platform column to each streaming service to maintain association\n",
    "netflix_df.loc[:, \"platform\"] = \"Netflix\"\n",
    "disney_df.loc[:, \"platform\"] = \"Disney+\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89f500a-0de7-4b22-88c6-f3e73cc852be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate Netflix and Disney+ dataframes\n",
    "combined_df = pd.concat([netflix_df, disney_df], ignore_index=True)\n",
    "len(combined_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe6b15e-2ca0-4b3e-94b2-6f6d7dba735e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find duplicate titles to remove from analysis\n",
    "duplicate_titles = combined_df[combined_df.duplicated(subset=['title'])]\n",
    "len(duplicate_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e650e028-c2d8-4da7-a136-ae33c029981f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the primary genre from listed_in by pulling the first values within the list\n",
    "combined_df['listed_in'] = combined_df['listed_in'].str.split(',')\n",
    "combined_df['primary_genre'] = combined_df['listed_in'].str.get(0)\n",
    "\n",
    "# blank_genre = combined_df[combined_df['primary_genre'].isna()]\n",
    "# len(blank_genre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee54b0cd-711b-4494-ac00-6c8ade5054e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean dataframe with columns of importance for data analysis\n",
    "combined_df = combined_df.loc[:, ['title', 'type','release_year', 'primary_genre', 'platform', 'date_added']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420bcb13-d684-4464-93c8-df985b91f55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'date_added' column to datetime\n",
    "combined_df['date_added'] = pd.to_datetime(combined_df['date_added'])\n",
    "# Extract year from 'date_added' and store it in a new column 'year_added'\n",
    "combined_df['year_added'] = combined_df['date_added'].dt.year\n",
    "\n",
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e8c877-3e60-4d44-b8fe-a387ca1b2391",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add empty columns for IMDb metadata to be pulled from API\n",
    "combined_df['imdb_id'] = ''\n",
    "combined_df['imdb_rating'] = ''\n",
    "combined_df['imdb_votes'] = ''\n",
    "combined_df['box_office_sales'] = ''\n",
    "combined_df['production_cost'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf24571-4c20-4819-a3c8-c2038f4c299c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter in field value replacements for genre normalization (i.e. Documentaries and Docuseries to Documentary)\n",
    "len(combined_df['primary_genre'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb314de-dc68-475e-bfa0-833759e26032",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST\n",
    "# Response 200 testing\n",
    "# url = \"http://www.omdbapi.com/?t=\"\n",
    "# api_key = \"&apikey=\" + omdb_api_key\n",
    "# response = requests.get(url + \"Aliens\" + api_key, verify=False)\n",
    "# print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a294b7-8a90-4307-9067-7bed60a8df80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST\n",
    "# Printing API URLs out\n",
    "\n",
    "# Establishing base URL for OMDB API\n",
    "# url = \"http://www.omdbapi.com/\"\n",
    "\n",
    "# Construct the API request URL with the title and API key\n",
    "# params = {\n",
    "#        'apikey': omdb_api_key,\n",
    "#    }\n",
    "\n",
    "# Loop through each title in the 'title' column of combined_df\n",
    "# for index, row in combined_df.iterrows():\n",
    "#    time.sleep(2) # Add a delay to avoid hitting the API too quickly\n",
    "    \n",
    "#    title = row['title']\n",
    "#    params['t'] = title # get title from combined_df\n",
    "    \n",
    "# Construct the API URL\n",
    "#    api_url = url + \"?\" + \"&\".join([f\"{key}={value}\" for key, value in params.items()])\n",
    "\n",
    "# Print the API URL for the current title\n",
    "#    print(\"API URL for\", title, \":\", api_url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6a0c9b-0cda-4a1d-a2a6-ad65af5d1611",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is being worked on - could not get api response to work (garrett) \n",
    "\n",
    "# Establishing base URL for OMDB API\n",
    "url = \"http://www.omdbapi.com/\"\n",
    "\n",
    "# Construct the API request URL with the title and API key\n",
    "params = {\n",
    "        'apikey': omdb_api_key,\n",
    "    }\n",
    "\n",
    "# Loop through each title in the 'title' column of combined_df\n",
    "for index, row in combined_df.iterrows():\n",
    "    time.sleep(2) # Add a delay to avoid hitting the API too quickly\n",
    "    \n",
    "    title = row['title'] # get title from current row\n",
    "    params['t'] = title # establish \"t\" parameter for current title\n",
    " \n",
    "   # Run an API request for each of the titles\n",
    "    try:\n",
    "        # Parse the JSON and retrieve data\n",
    "        omdb_response = requests.get(url, params=params, verify=False)\n",
    "        omdb_data = omdb_response.json()\n",
    "    \n",
    "    # Parse out OMDB ratings, votes, etc.\n",
    "        id = omdb_data.get('imdbID')\n",
    "        rating = omdb_data.get('imdbRating')\n",
    "        votes = omdb_data.get('imdbVotes')\n",
    "        box_office_sales = omdb_data.get('BoxOffice')\n",
    "        prod_cost = omdb_data.get('Production')\n",
    "        \n",
    "    # Assign OMDB information into combined_df\n",
    "        combined_df.at[index, \"imdb_id\"] = id\n",
    "        combined_df.at[index, \"imdb_rating\"] = rating\n",
    "        combined_df.at[index, \"imdb_votes\"] = votes \n",
    "        combined_df.at[index, \"box_office_sales\"] = box_office_sales \n",
    "        combined_df.at[index, \"production_cost\"] = prod_cost\n",
    "\n",
    "                             \n",
    "        print(f\"Data retrieved for '{title}': imdbRating = {rating}, imdbVotes = {votes}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to fetch data for '{title}': {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47a8d82-6b8a-4230-9019-18e38dc466c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
