{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3a0d4f-d325-42de-a7e3-3accbba18957",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies and Setup\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import time\n",
    "from scipy.stats import linregress\n",
    "\n",
    "\n",
    "# Import the OMDB API key\n",
    "from api_keys import omdb_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c6eebf0-05f6-4e2f-aecc-abb2ce804a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data files\n",
    "netflix_path = \"../data/netflix_titles.csv\"\n",
    "disney_path = \"../data/disney_plus_titles.csv\"\n",
    "prices_path = \"../data/subscription_prices.csv\"\n",
    "\n",
    "# Read the Netflix and Disney+ data\n",
    "netflix_data = pd.read_csv(netflix_path)\n",
    "disney_data = pd.read_csv(disney_path)\n",
    "prices_data = pd.read_csv(prices_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ec2244-9780-4525-a40c-879606dd26c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Netflix dataframe and review length\n",
    "netflix_df = pd.DataFrame(netflix_data)\n",
    "len(netflix_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304e048d-833f-4efb-94e2-d1eeca9afadd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Netflix date_added is the key column for filtering to 2019 - 2021 to align with Disney+ dataset date_added dates\n",
    "# The following steps trim the \"September 24, 2018\" dates to remove extra spaces, and converts date_added to date format for filtering\n",
    "netflix_df['date_added'] = netflix_df['date_added'].str.strip()\n",
    "netflix_df['date_added'] = pd.to_datetime(netflix_df['date_added'], errors='coerce')\n",
    "\n",
    "# There are a handful of blank date_added that will impact date filtering\n",
    "netflix_blank_dates = netflix_df[netflix_df['date_added'].isna()]\n",
    "len(netflix_blank_dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7a14de-654e-4728-926f-33754fce0557",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with blank dates\n",
    "netflix_df = netflix_df.dropna(subset=['date_added'])\n",
    "\n",
    "# Verify the number of rows with blank dates after dropping\n",
    "len(netflix_df[netflix_df['date_added'].isna()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d51d48f-85ff-4b88-bc7b-4841bad0f1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out for dates greater than January 1, 2019\n",
    "netflix_df = netflix_df.loc[(netflix_df['date_added'] >= '2019-01-01') & (netflix_df['date_added'] <= '2021-12-31')]\n",
    "len(netflix_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f5ac4b-5ad4-4347-8af3-2a8ad3a78844",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Disney+ dataframe and review length\n",
    "disney_df = pd.DataFrame(disney_data)\n",
    "disney_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd66992b-2b25-42a5-ac1c-5e45813d8801",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are a handful of blank date_added that will impact data\n",
    "disney_blank_dates = disney_df[disney_df['date_added'].isna()]\n",
    "len(disney_blank_dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00707854-6ed7-4565-9eca-a4d269603371",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with blank dates\n",
    "disney_df = disney_df.dropna(subset=['date_added'])\n",
    "\n",
    "# Verify the number of rows with blank dates after dropping\n",
    "len(disney_df[disney_df['date_added'].isna()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60ee9cd-4fa7-41ed-9bfe-ee5eda915b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Subscription Price dataframe and review length\n",
    "prices_df = pd.DataFrame(prices_data)\n",
    "len(prices_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c319f08-e34d-4719-8408-c6ebb8f209f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add platform column to each streaming service to maintain association\n",
    "netflix_df[\"platform\"] = \"Netflix\"\n",
    "disney_df[\"platform\"] = \"Disney+\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89f500a-0de7-4b22-88c6-f3e73cc852be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate Netflix and Disney+ dataframes\n",
    "combined_df = pd.concat([netflix_df, disney_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba97b5e0-f51a-40ad-a1fd-42459a9596f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e650e028-c2d8-4da7-a136-ae33c029981f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the primary genre from listed_in by pulling the first values within the list\n",
    "combined_df['listed_in'] = combined_df['listed_in'].str.split(',')\n",
    "combined_df['primary_genre'] = combined_df['listed_in'].str.get(0)\n",
    "combined_df.head()\n",
    "\n",
    "# blank_genre = combined_df[combined_df['primary_genre'].isna()]\n",
    "# len(blank_genre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee54b0cd-711b-4494-ac00-6c8ade5054e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean dataframe with columns of importance for data analysis\n",
    "combined_df = combined_df.loc[:, ['platform', 'show_id', 'type', 'title', 'date_added', 'release_year', 'primary_genre']]\n",
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e8c877-3e60-4d44-b8fe-a387ca1b2391",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add empty columns for IMDb metadata to be pulled from API\n",
    "combined_df['OMDb Rating'] = ''\n",
    "combined_df['OMDb Votes'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf24571-4c20-4819-a3c8-c2038f4c299c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter in field value replacements for genre normalization (i.e. Documentaries and Docuseries to Documentary)\n",
    "len(combined_df['primary_genre'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a294b7-8a90-4307-9067-7bed60a8df80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is being worked on - could not get api response to work (garrett) \n",
    "\n",
    "# Establishing base URL for OMDB API\n",
    "url = \"http://www.omdbapi.com/?\"\n",
    "\n",
    "# Construct the API request URL with the title and API key\n",
    "params = {\n",
    "        'apikey': omdb_api_key,\n",
    "    }\n",
    "\n",
    "# Loop through each title in the 'title' column of combined_df\n",
    "for index, row in combined_df.iterrows():\n",
    "    time.sleep(2) # Add a delay to avoid hitting the API too quickly\n",
    "\n",
    "    params['t'] = combined_df['title'] # get title from combined_df\n",
    "\n",
    "    # Establishing base URL for OMDB API\n",
    "    url = \"http://www.omdbapi.com/?\"\n",
    "    \n",
    "   # Run an API request for each of the titles\n",
    "    omdb_response = requests.get(url, params=params, verify=False)\n",
    "    print(omdb_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae895a0-2cbd-40df-a0ad-db2164e801c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# another try for api call structure\n",
    "# Establishing base URL for OMDB API\n",
    "url = \"http://www.omdbapi.com/?\"\n",
    "\n",
    "# Loop through each title in the 'title' column of combined_df\n",
    "for index, title in enumerate(combined_df['title']):\n",
    "    time.sleep(2) # Add a delay to avoid hitting the API too quickly\n",
    "    \n",
    "    # Construct the API request URL with the title and API key\n",
    "    params = {\n",
    "        'apikey': omdb_api_key,\n",
    "        't': title\n",
    "    }\n",
    "\n",
    "    # Run an API request for each of the titles\n",
    "    try:\n",
    "        # Parse the JSON and retrieve data\n",
    "        omdb_response = requests.get(url, params=params, verify=False)\n",
    "        omdb_data = response.json()\n",
    "    \n",
    "    # Parse out OMDB ratings, votes, etc.\n",
    "        rating = omdb_data[] # review and find correct column\n",
    "        votes = omdb_data[] # review and find correct column\n",
    "        \n",
    "    # Assign OMDB information into combined_df\n",
    "        combined_df.at[index, \"OMDb Rating\"] = rating, \n",
    "        combined_df.at[index, \"OMDb Votes\"] = rating \n",
    "                             # add in other co\n",
    "                            })\n",
    "    \n",
    " # If an error is experienced, skip the title\n",
    "    except:\n",
    "        print(\"Title not found. Skipping...\")\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
